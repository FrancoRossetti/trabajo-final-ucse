{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "50e1ae78",
   "metadata": {},
   "source": [
    "<h1>Extracci√≥n de datos mediante Tweepy</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38ead113",
   "metadata": {},
   "source": [
    "Este notebook tiene como finalidad realizar una recabaci√≥n de twits relacionados a los Juegos Ol√≠mpicos de Tokio 2020. Para realizar esta extracci√≥n de twits utilizaremos las siguientes herramientas: Tweepy y Pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0d6ec6cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tweepy\n",
    "import time\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "41fdb8de",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ./EDA_Twitter_Keys.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "611adf57",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Online authentication. Proveemos nuestro consumer_key y secret\n",
    "auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
    "#Proveemos nuestro access token y secret.\n",
    "auth.set_access_token(access_token,access_token_secret)\n",
    "api = tweepy.API(auth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bc0fa254",
   "metadata": {},
   "outputs": [],
   "source": [
    "#contenido del tweet\n",
    "tweets = []\n",
    "#cantidad de likes del tweet\n",
    "likes = []\n",
    "#tiempo en el cual el tweet se creo\n",
    "time = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d3487ffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "for tweet in tweepy.Cursor(api.search_tweets, \n",
    "                                 q = 'Olimpicos OR JJOO OR Tokio2020 -filter:retweets lang:es').items(1500):\n",
    "    text = tweet.text.replace('\\n',' ')\n",
    "    clean_tweet = re.sub(\"@[A-Za-z0-9]+\",\"\", text)\n",
    "    clean_tweet = re.sub(\"#[A-Za-z0-9]+\",\"\", clean_tweet)\n",
    "    clean_tweet = re.sub(r\"http\\S+\", \"\", clean_tweet)\n",
    "    clean_tweet = re.sub(r\"https\\S+\", \"\", clean_tweet)\n",
    "    tweets.append(clean_tweet)\n",
    "    likes.append(tweet.favorite_count)\n",
    "    time.append(tweet.created_at)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d458342d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'tweets':tweets,'likes':likes,'time':time})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c25bf3cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweets</th>\n",
       "      <th>likes</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Los juegos ol√≠mpicos de pekin üòÅ</td>\n",
       "      <td>0</td>\n",
       "      <td>2021-11-28 22:39:53+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>deportistas ol√≠mpicos vs youtubers</td>\n",
       "      <td>0</td>\n",
       "      <td>2021-11-28 22:38:29+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>deportistas olimpicos, asi los damos a conocer, tu imaginate que te plaque el de lanzamiento de pesos, ese mes te pillas la baja</td>\n",
       "      <td>0</td>\n",
       "      <td>2021-11-28 22:37:58+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>| SIN SABER CAMINAR, BEB√â DE 11 MESES YA PRACTICA SNOWBOARD Y CONMOCIONA LAS REDESüòÆüòÆ  -Wang Yuji de tan solo‚Ä¶</td>\n",
       "      <td>0</td>\n",
       "      <td>2021-11-28 22:30:00+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Como PF trabaj√≥ en Central, Wanderers y Pe√±arol. Dirigi√≥ la selecci√≥n de FUF(Federaci√≥n Uruguaya de F√∫tbol) durante‚Ä¶</td>\n",
       "      <td>3</td>\n",
       "      <td>2021-11-28 22:23:34+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1495</th>\n",
       "      <td>‚≠êÔ∏è Curiosidades hist√≥ricas sobre los Juegos Ol√≠mpicos...</td>\n",
       "      <td>0</td>\n",
       "      <td>2021-11-25 22:13:15+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1496</th>\n",
       "      <td>Todos los encuentros se podr√°n ver en ESPN por Star+.  El plantel argentino cuenta con catorce jugadores, de los cu‚Ä¶</td>\n",
       "      <td>0</td>\n",
       "      <td>2021-11-25 22:10:40+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1497</th>\n",
       "      <td>est√° considerando un boicot no oficial a los Juegos Ol√≠mpicos de Invierno Pek√≠n 2022</td>\n",
       "      <td>1</td>\n",
       "      <td>2021-11-25 22:03:20+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1498</th>\n",
       "      <td>Se nota que no viste los ol√≠mpicos, jugo desnudo todo ese torneo</td>\n",
       "      <td>1</td>\n",
       "      <td>2021-11-25 21:57:30+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1499</th>\n",
       "      <td>No nos hagamos trampas al solitario. La culpa es del jugador. Le ha pasado esto xq ‚Äú le hacia ilusi√≥n ‚Äú lo‚Ä¶</td>\n",
       "      <td>0</td>\n",
       "      <td>2021-11-25 21:56:53+00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1500 rows √ó 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                 tweets  \\\n",
       "0                                                                                                       Los juegos ol√≠mpicos de pekin üòÅ   \n",
       "1                                                                                                    deportistas ol√≠mpicos vs youtubers   \n",
       "2      deportistas olimpicos, asi los damos a conocer, tu imaginate que te plaque el de lanzamiento de pesos, ese mes te pillas la baja   \n",
       "3                        | SIN SABER CAMINAR, BEB√â DE 11 MESES YA PRACTICA SNOWBOARD Y CONMOCIONA LAS REDESüòÆüòÆ  -Wang Yuji de tan solo‚Ä¶    \n",
       "4                 Como PF trabaj√≥ en Central, Wanderers y Pe√±arol. Dirigi√≥ la selecci√≥n de FUF(Federaci√≥n Uruguaya de F√∫tbol) durante‚Ä¶    \n",
       "...                                                                                                                                 ...   \n",
       "1495                                                                          ‚≠êÔ∏è Curiosidades hist√≥ricas sobre los Juegos Ol√≠mpicos...    \n",
       "1496              Todos los encuentros se podr√°n ver en ESPN por Star+.  El plantel argentino cuenta con catorce jugadores, de los cu‚Ä¶    \n",
       "1497                                              est√° considerando un boicot no oficial a los Juegos Ol√≠mpicos de Invierno Pek√≠n 2022    \n",
       "1498                                                                   Se nota que no viste los ol√≠mpicos, jugo desnudo todo ese torneo   \n",
       "1499                       No nos hagamos trampas al solitario. La culpa es del jugador. Le ha pasado esto xq ‚Äú le hacia ilusi√≥n ‚Äú lo‚Ä¶    \n",
       "\n",
       "      likes                      time  \n",
       "0         0 2021-11-28 22:39:53+00:00  \n",
       "1         0 2021-11-28 22:38:29+00:00  \n",
       "2         0 2021-11-28 22:37:58+00:00  \n",
       "3         0 2021-11-28 22:30:00+00:00  \n",
       "4         3 2021-11-28 22:23:34+00:00  \n",
       "...     ...                       ...  \n",
       "1495      0 2021-11-25 22:13:15+00:00  \n",
       "1496      0 2021-11-25 22:10:40+00:00  \n",
       "1497      1 2021-11-25 22:03:20+00:00  \n",
       "1498      1 2021-11-25 21:57:30+00:00  \n",
       "1499      0 2021-11-25 21:56:53+00:00  \n",
       "\n",
       "[1500 rows x 3 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "160cc696",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweets</th>\n",
       "      <th>likes</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Los juegos ol√≠mpicos de pekin üòÅ</td>\n",
       "      <td>0</td>\n",
       "      <td>2021-11-28 22:39:53+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>deportistas ol√≠mpicos vs youtubers</td>\n",
       "      <td>0</td>\n",
       "      <td>2021-11-28 22:38:29+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>deportistas olimpicos, asi los damos a conocer, tu imaginate que te plaque el de lanzamiento de pesos, ese mes te pillas la baja</td>\n",
       "      <td>0</td>\n",
       "      <td>2021-11-28 22:37:58+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>| SIN SABER CAMINAR, BEB√â DE 11 MESES YA PRACTICA SNOWBOARD Y CONMOCIONA LAS REDESüòÆüòÆ  -Wang Yuji de tan solo‚Ä¶</td>\n",
       "      <td>0</td>\n",
       "      <td>2021-11-28 22:30:00+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Como PF trabaj√≥ en Central, Wanderers y Pe√±arol. Dirigi√≥ la selecci√≥n de FUF(Federaci√≥n Uruguaya de F√∫tbol) durante‚Ä¶</td>\n",
       "      <td>3</td>\n",
       "      <td>2021-11-28 22:23:34+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>üèÄ‚úÖ‚úÖüìñ‚úÖ‚úÖüìù‚úÖ‚úÖ Bueno, pero los JJOO son los 12 Mejores del Mundo. Selecciones de Gran Talento Mundial, Campeones de Euro‚Ä¶</td>\n",
       "      <td>7</td>\n",
       "      <td>2021-11-27 23:06:03+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>Bno les actualizo encontramos habitaci√≥n doble cerca donde viven mis amixes y al frente tienen piscinas entonces ca‚Ä¶</td>\n",
       "      <td>7</td>\n",
       "      <td>2021-11-27 23:03:43+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>¬°ENT√âRATE AQU√ç! Yorgelis Salazar: de perderse los Juegos Ol√≠mpicos a competir para ser campeona mundial de karate |</td>\n",
       "      <td>1</td>\n",
       "      <td>2021-11-27 23:00:01+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>Para cuando hacer ratio en los Juegos Ol√≠mpicos con Flakked como representante de Espa√±a</td>\n",
       "      <td>59</td>\n",
       "      <td>2021-11-27 22:52:09+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>S√≠ que se contar√≠a el Mundial del ‚Äò30 si se hubiese ganado. S‚Ä¶</td>\n",
       "      <td>0</td>\n",
       "      <td>2021-11-27 22:50:22+00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500 rows √ó 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                tweets  \\\n",
       "0                                                                                                      Los juegos ol√≠mpicos de pekin üòÅ   \n",
       "1                                                                                                   deportistas ol√≠mpicos vs youtubers   \n",
       "2     deportistas olimpicos, asi los damos a conocer, tu imaginate que te plaque el de lanzamiento de pesos, ese mes te pillas la baja   \n",
       "3                       | SIN SABER CAMINAR, BEB√â DE 11 MESES YA PRACTICA SNOWBOARD Y CONMOCIONA LAS REDESüòÆüòÆ  -Wang Yuji de tan solo‚Ä¶    \n",
       "4                Como PF trabaj√≥ en Central, Wanderers y Pe√±arol. Dirigi√≥ la selecci√≥n de FUF(Federaci√≥n Uruguaya de F√∫tbol) durante‚Ä¶    \n",
       "..                                                                                                                                 ...   \n",
       "495              üèÄ‚úÖ‚úÖüìñ‚úÖ‚úÖüìù‚úÖ‚úÖ Bueno, pero los JJOO son los 12 Mejores del Mundo. Selecciones de Gran Talento Mundial, Campeones de Euro‚Ä¶    \n",
       "496              Bno les actualizo encontramos habitaci√≥n doble cerca donde viven mis amixes y al frente tienen piscinas entonces ca‚Ä¶    \n",
       "497               ¬°ENT√âRATE AQU√ç! Yorgelis Salazar: de perderse los Juegos Ol√≠mpicos a competir para ser campeona mundial de karate |    \n",
       "498                                          Para cuando hacer ratio en los Juegos Ol√≠mpicos con Flakked como representante de Espa√±a    \n",
       "499                                                                    S√≠ que se contar√≠a el Mundial del ‚Äò30 si se hubiese ganado. S‚Ä¶    \n",
       "\n",
       "     likes                      time  \n",
       "0        0 2021-11-28 22:39:53+00:00  \n",
       "1        0 2021-11-28 22:38:29+00:00  \n",
       "2        0 2021-11-28 22:37:58+00:00  \n",
       "3        0 2021-11-28 22:30:00+00:00  \n",
       "4        3 2021-11-28 22:23:34+00:00  \n",
       "..     ...                       ...  \n",
       "495      7 2021-11-27 23:06:03+00:00  \n",
       "496      7 2021-11-27 23:03:43+00:00  \n",
       "497      1 2021-11-27 23:00:01+00:00  \n",
       "498     59 2021-11-27 22:52:09+00:00  \n",
       "499      0 2021-11-27 22:50:22+00:00  \n",
       "\n",
       "[500 rows x 3 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfTweets = df\n",
    "df.head(500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "56586761",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "now = datetime.now()\n",
    "df.to_csv('D:\\\\FACU\\\\TF_CSVs\\\\'+'tweets_' + str(now)[:16].replace(':','_') + '.csv',\n",
    "          index=True,\n",
    "          sep=';'\n",
    "         )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "50afebf2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pysentimiento\n",
      "  Using cached pysentimiento-0.3.0-py3-none-any.whl (20 kB)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.11.3 in c:\\users\\cacu\\documents\\tf_venv\\tf_proyect\\lib\\site-packages (from pysentimiento) (4.12.5)\n",
      "Collecting datasets<2.0.0,>=1.13.3\n",
      "  Using cached datasets-1.15.1-py3-none-any.whl (290 kB)\n",
      "Collecting sklearn<0.1,>=0.0\n",
      "  Using cached sklearn-0.0.tar.gz (1.1 kB)\n",
      "Requirement already satisfied: torch<2.0.0,>=1.9.0 in c:\\users\\cacu\\documents\\tf_venv\\tf_proyect\\lib\\site-packages (from pysentimiento) (1.10.0)\n",
      "Collecting emoji<2.0.0,>=1.6.1\n",
      "  Using cached emoji-1.6.1.tar.gz (170 kB)\n",
      "Requirement already satisfied: packaging in c:\\users\\cacu\\documents\\tf_venv\\tf_proyect\\lib\\site-packages (from datasets<2.0.0,>=1.13.3->pysentimiento) (21.2)\n",
      "Requirement already satisfied: pandas in c:\\users\\cacu\\documents\\tf_venv\\tf_proyect\\lib\\site-packages (from datasets<2.0.0,>=1.13.3->pysentimiento) (1.3.4)\n",
      "Requirement already satisfied: aiohttp in c:\\users\\cacu\\documents\\tf_venv\\tf_proyect\\lib\\site-packages (from datasets<2.0.0,>=1.13.3->pysentimiento) (3.8.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0.0,>=0.1.0 in c:\\users\\cacu\\documents\\tf_venv\\tf_proyect\\lib\\site-packages (from datasets<2.0.0,>=1.13.3->pysentimiento) (0.1.2)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in c:\\users\\cacu\\documents\\tf_venv\\tf_proyect\\lib\\site-packages (from datasets<2.0.0,>=1.13.3->pysentimiento) (4.62.3)\n",
      "Requirement already satisfied: multiprocess in c:\\users\\cacu\\documents\\tf_venv\\tf_proyect\\lib\\site-packages (from datasets<2.0.0,>=1.13.3->pysentimiento) (0.70.12.2)\n",
      "Requirement already satisfied: fsspec[http]>=2021.05.0 in c:\\users\\cacu\\documents\\tf_venv\\tf_proyect\\lib\\site-packages (from datasets<2.0.0,>=1.13.3->pysentimiento) (2021.11.0)\n",
      "Requirement already satisfied: xxhash in c:\\users\\cacu\\documents\\tf_venv\\tf_proyect\\lib\\site-packages (from datasets<2.0.0,>=1.13.3->pysentimiento) (2.0.2)\n",
      "Requirement already satisfied: pyarrow!=4.0.0,>=1.0.0 in c:\\users\\cacu\\documents\\tf_venv\\tf_proyect\\lib\\site-packages (from datasets<2.0.0,>=1.13.3->pysentimiento) (6.0.1)\n",
      "Requirement already satisfied: requests>=2.19.0 in c:\\users\\cacu\\documents\\tf_venv\\tf_proyect\\lib\\site-packages (from datasets<2.0.0,>=1.13.3->pysentimiento) (2.26.0)\n",
      "Requirement already satisfied: dill in c:\\users\\cacu\\documents\\tf_venv\\tf_proyect\\lib\\site-packages (from datasets<2.0.0,>=1.13.3->pysentimiento) (0.3.4)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\cacu\\documents\\tf_venv\\tf_proyect\\lib\\site-packages (from datasets<2.0.0,>=1.13.3->pysentimiento) (1.21.4)\n",
      "Requirement already satisfied: filelock in c:\\users\\cacu\\documents\\tf_venv\\tf_proyect\\lib\\site-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets<2.0.0,>=1.13.3->pysentimiento) (3.4.0)\n",
      "Requirement already satisfied: pyyaml in c:\\users\\cacu\\documents\\tf_venv\\tf_proyect\\lib\\site-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets<2.0.0,>=1.13.3->pysentimiento) (6.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\cacu\\documents\\tf_venv\\tf_proyect\\lib\\site-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets<2.0.0,>=1.13.3->pysentimiento) (3.10.0.2)\n",
      "Requirement already satisfied: pyparsing<3,>=2.0.2 in c:\\users\\cacu\\documents\\tf_venv\\tf_proyect\\lib\\site-packages (from packaging->datasets<2.0.0,>=1.13.3->pysentimiento) (2.4.7)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\cacu\\documents\\tf_venv\\tf_proyect\\lib\\site-packages (from requests>=2.19.0->datasets<2.0.0,>=1.13.3->pysentimiento) (1.26.7)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\cacu\\documents\\tf_venv\\tf_proyect\\lib\\site-packages (from requests>=2.19.0->datasets<2.0.0,>=1.13.3->pysentimiento) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\cacu\\documents\\tf_venv\\tf_proyect\\lib\\site-packages (from requests>=2.19.0->datasets<2.0.0,>=1.13.3->pysentimiento) (2021.10.8)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\cacu\\documents\\tf_venv\\tf_proyect\\lib\\site-packages (from requests>=2.19.0->datasets<2.0.0,>=1.13.3->pysentimiento) (3.3)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\cacu\\documents\\tf_venv\\tf_proyect\\lib\\site-packages (from sklearn<0.1,>=0.0->pysentimiento) (1.0.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\cacu\\documents\\tf_venv\\tf_proyect\\lib\\site-packages (from tqdm>=4.62.1->datasets<2.0.0,>=1.13.3->pysentimiento) (0.4.4)\n",
      "Requirement already satisfied: sacremoses in c:\\users\\cacu\\documents\\tf_venv\\tf_proyect\\lib\\site-packages (from transformers<5.0.0,>=4.11.3->pysentimiento) (0.0.46)\n",
      "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in c:\\users\\cacu\\documents\\tf_venv\\tf_proyect\\lib\\site-packages (from transformers<5.0.0,>=4.11.3->pysentimiento) (0.10.3)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\cacu\\documents\\tf_venv\\tf_proyect\\lib\\site-packages (from transformers<5.0.0,>=4.11.3->pysentimiento) (2021.11.10)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\cacu\\documents\\tf_venv\\tf_proyect\\lib\\site-packages (from aiohttp->datasets<2.0.0,>=1.13.3->pysentimiento) (1.2.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\cacu\\documents\\tf_venv\\tf_proyect\\lib\\site-packages (from aiohttp->datasets<2.0.0,>=1.13.3->pysentimiento) (21.2.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\cacu\\documents\\tf_venv\\tf_proyect\\lib\\site-packages (from aiohttp->datasets<2.0.0,>=1.13.3->pysentimiento) (1.7.2)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\cacu\\documents\\tf_venv\\tf_proyect\\lib\\site-packages (from aiohttp->datasets<2.0.0,>=1.13.3->pysentimiento) (5.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\cacu\\documents\\tf_venv\\tf_proyect\\lib\\site-packages (from aiohttp->datasets<2.0.0,>=1.13.3->pysentimiento) (1.2.0)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in c:\\users\\cacu\\documents\\tf_venv\\tf_proyect\\lib\\site-packages (from aiohttp->datasets<2.0.0,>=1.13.3->pysentimiento) (4.0.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in c:\\users\\cacu\\documents\\tf_venv\\tf_proyect\\lib\\site-packages (from pandas->datasets<2.0.0,>=1.13.3->pysentimiento) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2017.3 in c:\\users\\cacu\\documents\\tf_venv\\tf_proyect\\lib\\site-packages (from pandas->datasets<2.0.0,>=1.13.3->pysentimiento) (2021.3)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\cacu\\documents\\tf_venv\\tf_proyect\\lib\\site-packages (from python-dateutil>=2.7.3->pandas->datasets<2.0.0,>=1.13.3->pysentimiento) (1.16.0)\n",
      "Requirement already satisfied: joblib in c:\\users\\cacu\\documents\\tf_venv\\tf_proyect\\lib\\site-packages (from sacremoses->transformers<5.0.0,>=4.11.3->pysentimiento) (1.1.0)\n",
      "Requirement already satisfied: click in c:\\users\\cacu\\documents\\tf_venv\\tf_proyect\\lib\\site-packages (from sacremoses->transformers<5.0.0,>=4.11.3->pysentimiento) (8.0.3)\n",
      "Requirement already satisfied: scipy>=1.1.0 in c:\\users\\cacu\\documents\\tf_venv\\tf_proyect\\lib\\site-packages (from scikit-learn->sklearn<0.1,>=0.0->pysentimiento) (1.7.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\cacu\\documents\\tf_venv\\tf_proyect\\lib\\site-packages (from scikit-learn->sklearn<0.1,>=0.0->pysentimiento) (3.0.0)\n",
      "Using legacy 'setup.py install' for emoji, since package 'wheel' is not installed.\n",
      "Using legacy 'setup.py install' for sklearn, since package 'wheel' is not installed.\n",
      "Installing collected packages: sklearn, emoji, datasets, pysentimiento\n",
      "    Running setup.py install for sklearn: started\n",
      "    Running setup.py install for sklearn: finished with status 'done'\n",
      "    Running setup.py install for emoji: started\n",
      "    Running setup.py install for emoji: finished with status 'done'\n",
      "Successfully installed datasets-1.15.1 emoji-1.6.1 pysentimiento-0.3.0 sklearn-0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 21.2.4; however, version 21.3.1 is available.\n",
      "You should consider upgrading via the 'C:\\Users\\Cacu\\Documents\\TF_VENV\\TF_Proyect\\Scripts\\python.exe -m pip install --upgrade pip' command.\n",
      "WARNING: You are using pip version 21.2.4; however, version 21.3.1 is available.\n",
      "You should consider upgrading via the 'C:\\Users\\Cacu\\Documents\\TF_VENV\\TF_Proyect\\Scripts\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pysentimiento\n",
      "  Downloading pysentimiento-0.3.0-py3-none-any.whl (20 kB)\n",
      "Collecting datasets<2.0.0,>=1.13.3\n",
      "  Downloading datasets-1.15.1-py3-none-any.whl (290 kB)\n",
      "Collecting transformers<5.0.0,>=4.11.3\n",
      "  Downloading transformers-4.12.5-py3-none-any.whl (3.1 MB)\n",
      "Collecting sklearn<0.1,>=0.0\n",
      "  Downloading sklearn-0.0.tar.gz (1.1 kB)\n",
      "Collecting torch<2.0.0,>=1.9.0\n",
      "  Downloading torch-1.10.0-cp39-cp39-win_amd64.whl (226.5 MB)\n",
      "Collecting emoji<2.0.0,>=1.6.1\n",
      "  Downloading emoji-1.6.1.tar.gz (170 kB)\n",
      "Collecting multiprocess\n",
      "  Downloading multiprocess-0.70.12.2-py39-none-any.whl (128 kB)\n",
      "Collecting huggingface-hub<1.0.0,>=0.1.0\n",
      "  Downloading huggingface_hub-0.1.2-py3-none-any.whl (59 kB)\n",
      "Requirement already satisfied: requests>=2.19.0 in c:\\users\\cacu\\documents\\tf_venv\\tf_proyect\\lib\\site-packages (from datasets<2.0.0,>=1.13.3->pysentimiento) (2.26.0)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\cacu\\documents\\tf_venv\\tf_proyect\\lib\\site-packages (from datasets<2.0.0,>=1.13.3->pysentimiento) (1.21.4)\n",
      "Requirement already satisfied: pandas in c:\\users\\cacu\\documents\\tf_venv\\tf_proyect\\lib\\site-packages (from datasets<2.0.0,>=1.13.3->pysentimiento) (1.3.4)\n",
      "Collecting aiohttp\n",
      "  Downloading aiohttp-3.8.1-cp39-cp39-win_amd64.whl (554 kB)\n",
      "Collecting xxhash\n",
      "  Downloading xxhash-2.0.2-cp39-cp39-win_amd64.whl (35 kB)\n",
      "Collecting pyarrow!=4.0.0,>=1.0.0\n",
      "  Downloading pyarrow-6.0.1-cp39-cp39-win_amd64.whl (15.5 MB)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in c:\\users\\cacu\\documents\\tf_venv\\tf_proyect\\lib\\site-packages (from datasets<2.0.0,>=1.13.3->pysentimiento) (4.62.3)\n",
      "Collecting dill\n",
      "  Downloading dill-0.3.4-py2.py3-none-any.whl (86 kB)\n",
      "Collecting fsspec[http]>=2021.05.0\n",
      "  Downloading fsspec-2021.11.0-py3-none-any.whl (132 kB)\n",
      "Requirement already satisfied: packaging in c:\\users\\cacu\\documents\\tf_venv\\tf_proyect\\lib\\site-packages (from datasets<2.0.0,>=1.13.3->pysentimiento) (21.2)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\cacu\\documents\\tf_venv\\tf_proyect\\lib\\site-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets<2.0.0,>=1.13.3->pysentimiento) (3.10.0.2)\n",
      "Collecting filelock\n",
      "  Downloading filelock-3.4.0-py3-none-any.whl (9.8 kB)\n",
      "Collecting pyyaml\n",
      "  Downloading PyYAML-6.0-cp39-cp39-win_amd64.whl (151 kB)\n",
      "Requirement already satisfied: pyparsing<3,>=2.0.2 in c:\\users\\cacu\\documents\\tf_venv\\tf_proyect\\lib\\site-packages (from packaging->datasets<2.0.0,>=1.13.3->pysentimiento) (2.4.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\cacu\\documents\\tf_venv\\tf_proyect\\lib\\site-packages (from requests>=2.19.0->datasets<2.0.0,>=1.13.3->pysentimiento) (2021.10.8)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\cacu\\documents\\tf_venv\\tf_proyect\\lib\\site-packages (from requests>=2.19.0->datasets<2.0.0,>=1.13.3->pysentimiento) (3.3)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\cacu\\documents\\tf_venv\\tf_proyect\\lib\\site-packages (from requests>=2.19.0->datasets<2.0.0,>=1.13.3->pysentimiento) (1.26.7)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\cacu\\documents\\tf_venv\\tf_proyect\\lib\\site-packages (from requests>=2.19.0->datasets<2.0.0,>=1.13.3->pysentimiento) (2.0.7)\n",
      "Collecting scikit-learn\n",
      "  Downloading scikit_learn-1.0.1-cp39-cp39-win_amd64.whl (7.2 MB)\n",
      "Requirement already satisfied: colorama in c:\\users\\cacu\\documents\\tf_venv\\tf_proyect\\lib\\site-packages (from tqdm>=4.62.1->datasets<2.0.0,>=1.13.3->pysentimiento) (0.4.4)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\cacu\\documents\\tf_venv\\tf_proyect\\lib\\site-packages (from transformers<5.0.0,>=4.11.3->pysentimiento) (2021.11.10)\n",
      "Collecting tokenizers<0.11,>=0.10.1\n",
      "  Downloading tokenizers-0.10.3-cp39-cp39-win_amd64.whl (2.0 MB)\n",
      "Collecting sacremoses\n",
      "  Downloading sacremoses-0.0.46-py3-none-any.whl (895 kB)\n",
      "Collecting yarl<2.0,>=1.0\n",
      "  Downloading yarl-1.7.2-cp39-cp39-win_amd64.whl (122 kB)\n",
      "Collecting async-timeout<5.0,>=4.0.0a3\n",
      "  Downloading async_timeout-4.0.1-py3-none-any.whl (5.7 kB)\n",
      "Collecting frozenlist>=1.1.1\n",
      "  Downloading frozenlist-1.2.0-cp39-cp39-win_amd64.whl (83 kB)\n",
      "Collecting multidict<7.0,>=4.5\n",
      "  Downloading multidict-5.2.0-cp39-cp39-win_amd64.whl (45 kB)\n",
      "Collecting aiosignal>=1.1.2\n",
      "  Downloading aiosignal-1.2.0-py3-none-any.whl (8.2 kB)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\cacu\\documents\\tf_venv\\tf_proyect\\lib\\site-packages (from aiohttp->datasets<2.0.0,>=1.13.3->pysentimiento) (21.2.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in c:\\users\\cacu\\documents\\tf_venv\\tf_proyect\\lib\\site-packages (from pandas->datasets<2.0.0,>=1.13.3->pysentimiento) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2017.3 in c:\\users\\cacu\\documents\\tf_venv\\tf_proyect\\lib\\site-packages (from pandas->datasets<2.0.0,>=1.13.3->pysentimiento) (2021.3)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\cacu\\documents\\tf_venv\\tf_proyect\\lib\\site-packages (from python-dateutil>=2.7.3->pandas->datasets<2.0.0,>=1.13.3->pysentimiento) (1.16.0)\n",
      "Requirement already satisfied: click in c:\\users\\cacu\\documents\\tf_venv\\tf_proyect\\lib\\site-packages (from sacremoses->transformers<5.0.0,>=4.11.3->pysentimiento) (8.0.3)\n",
      "Requirement already satisfied: joblib in c:\\users\\cacu\\documents\\tf_venv\\tf_proyect\\lib\\site-packages (from sacremoses->transformers<5.0.0,>=4.11.3->pysentimiento) (1.1.0)\n",
      "Requirement already satisfied: scipy>=1.1.0 in c:\\users\\cacu\\documents\\tf_venv\\tf_proyect\\lib\\site-packages (from scikit-learn->sklearn<0.1,>=0.0->pysentimiento) (1.7.2)\n",
      "Collecting threadpoolctl>=2.0.0\n",
      "  Downloading threadpoolctl-3.0.0-py3-none-any.whl (14 kB)\n",
      "Using legacy 'setup.py install' for emoji, since package 'wheel' is not installed.\n",
      "Using legacy 'setup.py install' for sklearn, since package 'wheel' is not installed.\n",
      "Installing collected packages: multidict, frozenlist, yarl, async-timeout, aiosignal, threadpoolctl, pyyaml, fsspec, filelock, dill, aiohttp, xxhash, tokenizers, scikit-learn, sacremoses, pyarrow, multiprocess, huggingface-hub, transformers, torch, sklearn, emoji, datasets, pysentimiento\n",
      "    Running setup.py install for sklearn: started\n",
      "    Running setup.py install for sklearn: finished with status 'done'\n",
      "    Running setup.py install for emoji: started\n",
      "    Running setup.py install for emoji: finished with status 'done'\n",
      "Successfully installed aiohttp-3.8.1 aiosignal-1.2.0 async-timeout-4.0.1 datasets-1.15.1 dill-0.3.4 emoji-1.6.1 filelock-3.4.0 frozenlist-1.2.0 fsspec-2021.11.0 huggingface-hub-0.1.2 multidict-5.2.0 multiprocess-0.70.12.2 pyarrow-6.0.1 pysentimiento-0.3.0 pyyaml-6.0 sacremoses-0.0.46 scikit-learn-1.0.1 sklearn-0.0 threadpoolctl-3.0.0 tokenizers-0.10.3 torch-1.10.0 transformers-4.12.5 xxhash-2.0.2 yarl-1.7.2\n"
     ]
    }
   ],
   "source": [
    "# Install a pip package in the current Jupyter kernel\n",
    "import sys\n",
    "!{sys.executable} -m pip install pysentimiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ac3447f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6561cb2395824eefa272c4cc9244f14c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/334 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "227cb3006f404976b6ec07f7cf1c6e36",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/150 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b6e140eb2b3e4cb8b6f7488e517191d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/838k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d27c26264ff474b8310bd59c12d804f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/925 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "863f3040cd444e20ac6cb78030e39500",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/415M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pysentimiento import create_analyzer\n",
    "analyzer = create_analyzer(task=\"sentiment\", lang=\"es\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "121ddc32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AnalyzerOutput(output=POS, probas={POS: 0.994, NEG: 0.003, NEU: 0.003})"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analyzer.predict(\"Qu√© gran jugador es Messi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9fa05b93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ÄúLa vela es un deporte que puede practicar cualquier persona, no importa la discapacidad‚Äù Scott Perry, ex President‚Ä¶ \n",
      "AnalyzerOutput(output=NEU, probas={NEU: 0.978, POS: 0.019, NEG: 0.002})\n",
      " ¬´ un lugar entre los ol√≠mpicos. No ten√≠a tiempo para aquello ahora mismo, iba a bajar a la tierra, y t‚Ä¶ \n",
      "AnalyzerOutput(output=NEU, probas={NEU: 0.924, POS: 0.053, NEG: 0.022})\n",
      "Todos los encuentros se podr√°n ver en ESPN por Star+.  El plantel argentino cuenta con catorce jugadores, de los cu‚Ä¶ \n",
      "AnalyzerOutput(output=NEU, probas={NEU: 0.928, POS: 0.061, NEG: 0.011})\n",
      " est√° considerando un boicot no oficial a los Juegos Ol√≠mpicos de Invierno Pek√≠n 2022 \n",
      "AnalyzerOutput(output=NEU, probas={NEU: 0.851, NEG: 0.145, POS: 0.004})\n",
      "  Se nota que no viste los ol√≠mpicos, jugo desnudo todo ese torneo\n",
      "AnalyzerOutput(output=NEG, probas={NEG: 0.982, NEU: 0.016, POS: 0.002})\n",
      " No nos hagamos trampas al solitario. La culpa es del jugador. Le ha pasado esto xq ‚Äú le hacia ilusi√≥n ‚Äú lo‚Ä¶ \n",
      "AnalyzerOutput(output=NEG, probas={NEG: 0.901, NEU: 0.097, POS: 0.002})\n",
      " Rema como loco el gordo, lo llevas a los Juegos Ol√≠mpicos y te trae medallas el Boxeo y remo el hijo de puta\n",
      "AnalyzerOutput(output=NEG, probas={NEG: 0.976, NEU: 0.019, POS: 0.005})\n",
      "No se que me enfada m√°s, los que afirman que Girona ya ser√° un ascenso, o los que hablando de los JJOO afirman sin‚Ä¶ \n",
      "AnalyzerOutput(output=NEG, probas={NEG: 0.991, NEU: 0.009, POS: 0.000})\n",
      "_F_S_A09   La neta  Ese vato seguro que no vio los ol√≠mpicos\n",
      "AnalyzerOutput(output=NEG, probas={NEG: 0.960, NEU: 0.037, POS: 0.003})\n",
      " 11 ceremonias de inauguraci√≥n entre ser atleta y reportera JCC, JP y JJOO. . La emoci√≥n siempre‚Ä¶ \n",
      "AnalyzerOutput(output=NEU, probas={NEU: 0.908, POS: 0.087, NEG: 0.005})\n",
      "Si os gusta el deporte, los Juegos Ol√≠mpicos sigan esta cuenta  y ojead su web, que es estupenda.\n",
      "AnalyzerOutput(output=POS, probas={POS: 0.995, NEU: 0.005, NEG: 0.000})\n",
      " Buenas tard√©s, en los ol√≠mpicos,en el ciclismo en atletismo en todos los deportes se premia y se rec‚Ä¶ \n",
      "AnalyzerOutput(output=POS, probas={POS: 0.581, NEU: 0.416, NEG: 0.003})\n",
      "  _riverogc 22) Muere la ciclista ol√≠mpica Olivia Podmore. 23) Muere el velocista Camer‚Ä¶ \n",
      "AnalyzerOutput(output=NEU, probas={NEU: 0.688, NEG: 0.291, POS: 0.022})\n",
      " saludos rrecrackk, por supuesto debe de haber medalla para el segundo, es un premio al esfuerzo, que‚Ä¶ \n",
      "AnalyzerOutput(output=POS, probas={POS: 0.895, NEU: 0.105, NEG: 0.001})\n",
      "  Una medalla es un premio al esfuerzo, es lo mismo si no le dan t√≠tulo al campe√≥n? Es el p‚Ä¶ \n",
      "AnalyzerOutput(output=NEG, probas={NEG: 0.706, NEU: 0.288, POS: 0.006})\n",
      " _ No seras muy graciosa vos no?? Raja de aca que te fuiste a los juegos olimpicos solamente a cojer no a competir\n",
      "AnalyzerOutput(output=NEG, probas={NEG: 0.993, NEU: 0.006, POS: 0.001})\n",
      "Salvador Hern√°ndez por su √∫ltimo ciclo Paral√≠mpico.: ¬†* Ya inici√≥ preparaci√≥n¬†rumbo a los Juegos Ol√≠mpicos de Par√≠s‚Ä¶ \n",
      "AnalyzerOutput(output=NEU, probas={NEU: 0.948, POS: 0.045, NEG: 0.007})\n",
      " Buenas tardes, se debe dar medalla tal como se hace en los Juegos Ol√≠mpicos, debe haber sanci√≥n a qu‚Ä¶ \n",
      "AnalyzerOutput(output=NEU, probas={NEU: 0.983, NEG: 0.011, POS: 0.006})\n",
      "Ol√≠mpicos\n",
      "AnalyzerOutput(output=NEU, probas={NEU: 0.658, POS: 0.243, NEG: 0.099})\n",
      "_casalegno  Los ol√≠mpicos/as son gente de otro planeta. Tuve la suerte de entrenar con una de ellas.‚Ä¶ \n",
      "AnalyzerOutput(output=POS, probas={POS: 0.994, NEU: 0.005, NEG: 0.001})\n",
      " Un 24 de Noviembre del 1991 parti√≥ a la Eternidad,el nacido en Zanz√≠bar y criado en Londres.Ya no lleg√≥ a‚Ä¶ \n",
      "AnalyzerOutput(output=NEG, probas={NEG: 0.582, NEU: 0.414, POS: 0.003})\n",
      "Ent√©rate aqu√≠ üëâ Yorgelis Salazar: de perderse los Juegos Ol√≠mpicos a competir para ser campeona mundial de karate \n",
      "AnalyzerOutput(output=NEU, probas={NEU: 0.932, NEG: 0.048, POS: 0.020})\n",
      "‚≠êÔ∏è Curiosidades hist√≥ricas sobre los Juegos Ol√≠mpicos... \n",
      "AnalyzerOutput(output=NEU, probas={NEU: 0.898, POS: 0.087, NEG: 0.014})\n",
      "UN BRONCE MUY CARO  Lesi√≥n de los Juegos Ol√≠mpicos le cuesta a Diego Lainez su lugar en el Betis.‚Ä¶ \n",
      "AnalyzerOutput(output=NEG, probas={NEG: 0.998, NEU: 0.001, POS: 0.000})\n",
      "¬øC√≥mo se podr√° ir de los aeropuertos de Par√≠s-Charles de Gaulle al de Le Bourget? En taxi a√©reo. No ser√≠a el √∫nico‚Ä¶ \n",
      "AnalyzerOutput(output=NEU, probas={NEU: 0.930, NEG: 0.066, POS: 0.004})\n",
      " | Al igual que Estados Unidos y el Reino Unido, el pa√≠s oce√°nico analiza no enviar ning√∫n funciona‚Ä¶ \n",
      "AnalyzerOutput(output=NEU, probas={NEU: 0.987, NEG: 0.010, POS: 0.004})\n",
      " bokuto en el de 500 y oikawa que nos llevo a los olimpicos en el de 1000 minimo\n",
      "AnalyzerOutput(output=NEU, probas={NEU: 0.917, NEG: 0.065, POS: 0.018})\n",
      "alex morgan y rapinoe lo maximo que han hecho este a√±o ha sido marcar un penalti en los JJOO y renard?? que ha hech‚Ä¶ \n",
      "AnalyzerOutput(output=NEG, probas={NEG: 0.987, NEU: 0.011, POS: 0.001})\n",
      " Si pierden mucha poblaci√≥n, en los pr√≥ximos JJOO igual ganan menos medallas.\n",
      "AnalyzerOutput(output=NEU, probas={NEU: 0.877, NEG: 0.115, POS: 0.008})\n",
      "Mi estimado JOTITA, hist√≥ricamente los deportes masivos triunfantes son ocupados pol√≠ticamente. , Ejm juegos Ol√≠mpi‚Ä¶ \n",
      "AnalyzerOutput(output=NEU, probas={NEU: 0.987, POS: 0.010, NEG: 0.002})\n",
      "Cada d√≠a m√°s cerca esa, m√°s que merecida, medalla de bronce de los JJOO  para Sete Benavides üëèüëèüëè  \n",
      "AnalyzerOutput(output=POS, probas={POS: 0.537, NEU: 0.450, NEG: 0.013})\n",
      "   ___     ‚Ä¶ \n",
      "AnalyzerOutput(output=NEU, probas={NEU: 0.660, POS: 0.172, NEG: 0.169})\n",
      "¬°Grandes campeones deportivos estar√°n en !  Varios medallistas ol√≠mpicos de Tokio 2020 participar√°n e‚Ä¶ \n",
      "AnalyzerOutput(output=POS, probas={POS: 0.975, NEU: 0.022, NEG: 0.003})\n",
      " es verdad que  ya no indultar√° a los \"presos pol√≠ticos\"? ü§£ü§£ü§£ Ni Tom√°s Gonz√°lez se atrev‚Ä¶ \n",
      "AnalyzerOutput(output=NEU, probas={NEU: 0.785, NEG: 0.198, POS: 0.017})\n",
      "     5 Davis y dos oros Ol√≠mpicos para Espa√±a. Tienes que s‚Ä¶ \n",
      "AnalyzerOutput(output=POS, probas={POS: 0.842, NEU: 0.129, NEG: 0.030})\n",
      "31-BEIJING 2008 Diego fue omnipresente en los Juegos Ol√≠mpicos en cuanto deporte hubiera un argentino. Los vivi√≥ co‚Ä¶ \n",
      "AnalyzerOutput(output=NEU, probas={NEU: 0.754, POS: 0.238, NEG: 0.008})\n",
      "VTV CANAL 8  dice: Juegos Ol√≠mpicos de Invierno de Beijing volver√° a reunir a atletas de todo el mundo 14 a√±os desp‚Ä¶ \n",
      "AnalyzerOutput(output=NEU, probas={NEU: 0.965, POS: 0.026, NEG: 0.008})\n",
      "Juegos Ol√≠mpicos de Invierno de Beijing volver√° a reunir a atletas de todo el mundo 14 a√±os despu√©s‚Ä¶ \n",
      "AnalyzerOutput(output=NEU, probas={NEU: 0.913, POS: 0.074, NEG: 0.013})\n",
      "  Sin ninguna duda, todos se preparan para el Tour de France no para los JJOO\n",
      "AnalyzerOutput(output=NEU, probas={NEU: 0.974, POS: 0.019, NEG: 0.006})\n",
      "üì±- Un programa para todos los gustos  üó£Ô∏è‚ÄúEn diciembre cumplo 30 a√±os de carrera. Son 7  y 3 mundi‚Ä¶ \n",
      "AnalyzerOutput(output=NEU, probas={NEU: 0.949, POS: 0.046, NEG: 0.005})\n"
     ]
    }
   ],
   "source": [
    "for tuit in df2[:40].tweets:\n",
    "    print(tuit)\n",
    "    print(analyzer.predict(tuit))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "64bd8722",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn in c:\\users\\cacu\\documents\\tf_venv\\tf_proyect\\lib\\site-packages (1.0.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\cacu\\documents\\tf_venv\\tf_proyect\\lib\\site-packages (from scikit-learn) (3.0.0)\n",
      "Requirement already satisfied: scipy>=1.1.0 in c:\\users\\cacu\\documents\\tf_venv\\tf_proyect\\lib\\site-packages (from scikit-learn) (1.7.2)\n",
      "Requirement already satisfied: joblib>=0.11 in c:\\users\\cacu\\documents\\tf_venv\\tf_proyect\\lib\\site-packages (from scikit-learn) (1.1.0)\n",
      "Requirement already satisfied: numpy>=1.14.6 in c:\\users\\cacu\\documents\\tf_venv\\tf_proyect\\lib\\site-packages (from scikit-learn) (1.21.4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 21.2.4; however, version 21.3.1 is available.\n",
      "You should consider upgrading via the 'C:\\Users\\Cacu\\Documents\\TF_VENV\\TF_Proyect\\Scripts\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install scikit-learn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "75798229",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'joblib' from 'sklearn.externals' (C:\\Users\\Cacu\\Documents\\TF_VENV\\TF_Proyect\\lib\\site-packages\\sklearn\\externals\\__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_7764/2202668904.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mclassifier\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Documents\\TF_VENV\\TF_Proyect\\lib\\site-packages\\classifier\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0msentimentPipeline\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mscript_global\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Documents\\TF_VENV\\TF_Proyect\\lib\\site-packages\\classifier\\sentimentPipeline.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexternals\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mjoblib\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mre\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mjson\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfeature_extraction\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtext\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mTfidfVectorizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mCountVectorizer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfeature_selection\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mSelectKBest\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mchi2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'joblib' from 'sklearn.externals' (C:\\Users\\Cacu\\Documents\\TF_VENV\\TF_Proyect\\lib\\site-packages\\sklearn\\externals\\__init__.py)"
     ]
    }
   ],
   "source": [
    "from classifier import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea5b776a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
